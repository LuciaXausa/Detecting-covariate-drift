{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to generate a csv file with the results of the metrics applied on synthethic drifted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('Utils'))\n",
    "sys.path.append(os.path.abspath('data'))\n",
    "sys.path.append(os.path.abspath('thresholds_and_results'))\n",
    "\n",
    "from utils_generateTests import split_data, reduced_on_drift_kdim, test_on_reduced_kdim\n",
    "from utils_dimRedDef import find_dimensions_number, initialize_DimReduction, scale_dataset, init_scaler\n",
    "from utils_resNet import df_from_folder, init_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "seed_split = 2\n",
    "# seed_split = 1\n",
    "seed_drift = 10\n",
    "seed_metrics = 100\n",
    "info_dataset = [seed_split, seed_drift, seed_metrics]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dimensions for dimensionality reduction\n",
    "k = 6\n",
    "# csv file where saving results\n",
    "resultFile = 'thresholds_and_results/2dim/devResults_2d.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the resNet, used as pre-process for each image in order to extract more relevant feature and not work directly with pixels\n",
    "model = init_resnet(seed_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining folder directories (created in drift_and_thresholds.ipynb)\n",
    "intensity_path = 'data/synthetic_data/drift_intensity/'\n",
    "gaussian_path_1 = 'data/synthetic_data/drift_gaussian_1/'\n",
    "gaussian_path_10 = 'data/synthetic_data/drift_gaussian_10/'\n",
    "gaussian_path_100 = 'data/synthetic_data/drift_gaussian_100/'\n",
    "input_path = 'data/synthetic_data/black/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe in train, test, validation sets, as lists\n",
    "train_list, test_list, val_list = split_data(input_path, seed_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes needed as input for the governance pipeline \n",
    "train = df_from_folder(input_path, model,  train_list)\n",
    "test = df_from_folder(input_path,  model,  test_list)\n",
    "val = df_from_folder(input_path,  model, val_list)\n",
    "val_intensity = df_from_folder(intensity_path, model, val_list)\n",
    "val_gaussian_1 = df_from_folder(gaussian_path_1, model,  val_list)\n",
    "val_gaussian_10 = df_from_folder(gaussian_path_10,  model, val_list)\n",
    "val_gaussian_100 = df_from_folder(gaussian_path_100,  model, val_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find PCA with components that get 80% of variance on test set as done in the paper 'Failing Loudly' by Rabanser & co. to find the number of components to reduce the dataframes to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = find_dimensions_number(test)      \n",
    "k=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize dimensionality reductors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize scaler for autoencoder\n",
    "standard_scaler = init_scaler(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling source dataset\n",
    "train_scaled = scale_dataset(train, standard_scaler)\n",
    "test_scaled = scale_dataset(test, standard_scaler)\n",
    "val_scaled = scale_dataset(val, standard_scaler)\n",
    "# scaling drifted dataset\n",
    "val_intensity_scaled = scale_dataset(val_intensity, standard_scaler)\n",
    "val_gaussian_1_scaled = scale_dataset(val_gaussian_1, standard_scaler)\n",
    "val_gaussian_10_scaled = scale_dataset(val_gaussian_10, standard_scaler)\n",
    "val_gaussian_100_scaled = scale_dataset(val_gaussian_100, standard_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dimensionality reduction\n",
    "reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer = initialize_DimReduction(seed_metrics, test,  train_scaled, test_scaled, k=k)   #k not specified: k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply dimensionality reduction\n",
    "test_dim_red, info_drift = reduced_on_drift_kdim(test,  info_dataset,  reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer, )\n",
    "val_dim_red, info_drift_val= reduced_on_drift_kdim(val,  info_dataset,  reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer,)\n",
    "#  on drifted\n",
    "gau1_dim_red, info_drift_g1 = reduced_on_drift_kdim(val_gaussian_1, info_dataset, reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer ,  sigma=1, drift='Gaussian')\n",
    "gau10_dim_red, info_drift_g10 = reduced_on_drift_kdim(val_gaussian_10, info_dataset, reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer,   sigma=10, drift='Gaussian')\n",
    "gau100_dim_red, info_drift_g100 = reduced_on_drift_kdim(val_gaussian_100, info_dataset, reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer,   sigma=100, drift='Gaussian')\n",
    "intensity_dim_red, info_drift_i = reduced_on_drift_kdim(val_intensity, info_dataset, reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer ,  sigma=42, drift='intensity')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_on_reduced_kdim(val, test,  val_dim_red, test_dim_red, seed_metrics, resultFile, info_drift = info_drift_val, k=k)\n",
    "test_on_reduced_kdim(val_gaussian_1, test, gau1_dim_red, test_dim_red,  seed_metrics, resultFile, info_drift_g1, k)\n",
    "test_on_reduced_kdim(val_gaussian_10, test,  gau10_dim_red, test_dim_red, seed_metrics, resultFile, info_drift_g10, k)\n",
    "test_on_reduced_kdim(val_gaussian_100, test, gau100_dim_red, test_dim_red,  seed_metrics, resultFile, info_drift_g100, k)\n",
    "test_on_reduced_kdim(val_intensity, test, intensity_dim_red, test_dim_red, seed_metrics, resultFile, info_drift_i, k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

