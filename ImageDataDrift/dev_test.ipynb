{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to generate a csv file with the results of the metrics applied on synthethic drifted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath('Utils'))\n",
    "sys.path.append(os.path.abspath('data'))\n",
    "sys.path.append(os.path.abspath('thresholds_and_results'))\n",
    "\n",
    "from utils_generateTests import split_data, reduced_on_drift_kdim, test_on_reduced_kdim\n",
    "from utils_dimRedDef import find_dimensions_number, initialize_DimReduction, scale_dataset, init_scaler\n",
    "from utils_resNet import df_from_folder, init_resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "seed_split = 2\n",
    "# seed_split = 1\n",
    "seed_drift = 10\n",
    "seed_metrics = 100\n",
    "info_dataset = [seed_split, seed_drift, seed_metrics]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dimensions for dimensionality reduction\n",
    "k = 6\n",
    "# csv file where saving results\n",
    "resultFile = 'thresholds_and_results/2dim/devResults_2d.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# initialize the resNet, used as pre-process for each image in order to extract more relevant feature and not work directly with pixels\n",
    "model = init_resnet(seed_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining folder directories (created in drift_and_thresholds.ipynb)\n",
    "intensity_path = 'data/synthetic_data/drift_intensity/'\n",
    "gaussian_path_1 = 'data/synthetic_data/drift_gaussian_1/'\n",
    "gaussian_path_10 = 'data/synthetic_data/drift_gaussian_10/'\n",
    "gaussian_path_100 = 'data/synthetic_data/drift_gaussian_100/'\n",
    "input_path = 'data/synthetic_data/black/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataframe in train, test, validation sets, as lists\n",
    "train_list, test_list, val_list = split_data(input_path, seed_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# create dataframes needed as input for the governance pipeline \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train \u001b[38;5;241m=\u001b[39m \u001b[43mdf_from_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtrain_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m test \u001b[38;5;241m=\u001b[39m df_from_folder(input_path,  model,  test_list)\n\u001b[0;32m      4\u001b[0m val \u001b[38;5;241m=\u001b[39m df_from_folder(input_path,  model, val_list)\n",
      "File \u001b[1;32md:\\UNI\\MAGISTRALE\\TESI\\orobix-governance_stage-7ea3ff331b1f\\imageDataDrift\\Utils\\utils_resNet.py:59\u001b[0m, in \u001b[0;36mdf_from_folder\u001b[1;34m(folder_path, model, desired_list)\u001b[0m\n\u001b[0;32m     57\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(folder_path\u001b[38;5;241m+\u001b[39mimage_path)\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# apply model and get array\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_selection_from_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m       \n\u001b[0;32m     60\u001b[0m     arrayList\u001b[38;5;241m.\u001b[39mappend(arr)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# A dataframe is needed in order to re-apply the same procedure for governance pipeline defined on tabular data    \u001b[39;00m\n",
      "File \u001b[1;32md:\\UNI\\MAGISTRALE\\TESI\\orobix-governance_stage-7ea3ff331b1f\\imageDataDrift\\Utils\\utils_resNet.py:37\u001b[0m, in \u001b[0;36mfeature_selection_from_img\u001b[1;34m(img, model)\u001b[0m\n\u001b[0;32m     35\u001b[0m tensor_img \u001b[38;5;241m=\u001b[39m img_transformation(img)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 37\u001b[0m     feature \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_img\u001b[49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m#feature is tensor of size [1, 512, 1, 1]\u001b[39;00m\n\u001b[0;32m     38\u001b[0m rfeat \u001b[38;5;241m=\u001b[39m feature\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     39\u001b[0m arr \u001b[38;5;241m=\u001b[39m rfeat\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\resnet.py:93\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     90\u001b[0m identity \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     92\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m---> 93\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:175\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    168\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2482\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2480\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2484\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create dataframes needed as input for the governance pipeline \n",
    "train = df_from_folder(input_path, model,  train_list)\n",
    "test = df_from_folder(input_path,  model,  test_list)\n",
    "val = df_from_folder(input_path,  model, val_list)\n",
    "val_intensity = df_from_folder(intensity_path, model, val_list)\n",
    "val_gaussian_1 = df_from_folder(gaussian_path_1, model,  val_list)\n",
    "val_gaussian_10 = df_from_folder(gaussian_path_10,  model, val_list)\n",
    "val_gaussian_100 = df_from_folder(gaussian_path_100,  model, val_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find PCA with components that get 80% of variance on test set as done in the paper 'Failing Loudly' by Rabanser & co. to find the number of components to reduce the dataframes to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = find_dimensions_number(test)      \n",
    "k=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize dimensionality reductors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178436</td>\n",
       "      <td>0.110992</td>\n",
       "      <td>1.646519</td>\n",
       "      <td>0.461198</td>\n",
       "      <td>0.576611</td>\n",
       "      <td>0.440900</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>1.356820</td>\n",
       "      <td>1.447873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412051</td>\n",
       "      <td>1.002263</td>\n",
       "      <td>0.062367</td>\n",
       "      <td>0.291720</td>\n",
       "      <td>0.514440</td>\n",
       "      <td>0.285739</td>\n",
       "      <td>0.545336</td>\n",
       "      <td>0.095519</td>\n",
       "      <td>0.406564</td>\n",
       "      <td>0.453166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.157798</td>\n",
       "      <td>0.182142</td>\n",
       "      <td>1.353120</td>\n",
       "      <td>0.302760</td>\n",
       "      <td>0.396004</td>\n",
       "      <td>0.293400</td>\n",
       "      <td>0.443676</td>\n",
       "      <td>0.235815</td>\n",
       "      <td>1.362739</td>\n",
       "      <td>1.114463</td>\n",
       "      <td>...</td>\n",
       "      <td>0.748258</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>0.073889</td>\n",
       "      <td>0.395346</td>\n",
       "      <td>0.848227</td>\n",
       "      <td>0.415397</td>\n",
       "      <td>0.433709</td>\n",
       "      <td>0.223282</td>\n",
       "      <td>0.281199</td>\n",
       "      <td>0.227835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279244</td>\n",
       "      <td>0.173864</td>\n",
       "      <td>1.204811</td>\n",
       "      <td>0.534460</td>\n",
       "      <td>0.455656</td>\n",
       "      <td>0.253122</td>\n",
       "      <td>0.358214</td>\n",
       "      <td>0.369609</td>\n",
       "      <td>1.148496</td>\n",
       "      <td>0.855464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.608319</td>\n",
       "      <td>0.399806</td>\n",
       "      <td>0.100406</td>\n",
       "      <td>0.550980</td>\n",
       "      <td>1.274041</td>\n",
       "      <td>0.404865</td>\n",
       "      <td>0.284395</td>\n",
       "      <td>0.353530</td>\n",
       "      <td>0.579028</td>\n",
       "      <td>0.341356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.141640</td>\n",
       "      <td>0.115692</td>\n",
       "      <td>1.701929</td>\n",
       "      <td>0.543042</td>\n",
       "      <td>0.615419</td>\n",
       "      <td>0.434615</td>\n",
       "      <td>0.388934</td>\n",
       "      <td>0.364442</td>\n",
       "      <td>1.280295</td>\n",
       "      <td>1.498631</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356081</td>\n",
       "      <td>1.112890</td>\n",
       "      <td>0.094736</td>\n",
       "      <td>0.261186</td>\n",
       "      <td>0.535325</td>\n",
       "      <td>0.439572</td>\n",
       "      <td>0.627597</td>\n",
       "      <td>0.107170</td>\n",
       "      <td>0.455620</td>\n",
       "      <td>0.319513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194263</td>\n",
       "      <td>0.224569</td>\n",
       "      <td>1.435983</td>\n",
       "      <td>0.387076</td>\n",
       "      <td>0.667164</td>\n",
       "      <td>1.001340</td>\n",
       "      <td>0.635107</td>\n",
       "      <td>0.232524</td>\n",
       "      <td>1.038372</td>\n",
       "      <td>0.860122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.773579</td>\n",
       "      <td>0.484655</td>\n",
       "      <td>0.131175</td>\n",
       "      <td>0.604059</td>\n",
       "      <td>1.274567</td>\n",
       "      <td>0.444980</td>\n",
       "      <td>0.838310</td>\n",
       "      <td>0.115054</td>\n",
       "      <td>0.649787</td>\n",
       "      <td>0.242541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.154442</td>\n",
       "      <td>0.177273</td>\n",
       "      <td>1.153289</td>\n",
       "      <td>0.312910</td>\n",
       "      <td>0.452722</td>\n",
       "      <td>0.187168</td>\n",
       "      <td>0.375944</td>\n",
       "      <td>0.239255</td>\n",
       "      <td>1.366748</td>\n",
       "      <td>0.920817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.796336</td>\n",
       "      <td>0.431720</td>\n",
       "      <td>0.063977</td>\n",
       "      <td>0.343481</td>\n",
       "      <td>0.856915</td>\n",
       "      <td>0.324841</td>\n",
       "      <td>0.377139</td>\n",
       "      <td>0.310673</td>\n",
       "      <td>0.318942</td>\n",
       "      <td>0.454552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.129999</td>\n",
       "      <td>0.200820</td>\n",
       "      <td>1.077242</td>\n",
       "      <td>0.186530</td>\n",
       "      <td>0.494382</td>\n",
       "      <td>0.203442</td>\n",
       "      <td>0.653930</td>\n",
       "      <td>0.407251</td>\n",
       "      <td>1.314530</td>\n",
       "      <td>0.551926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795509</td>\n",
       "      <td>0.336958</td>\n",
       "      <td>0.080450</td>\n",
       "      <td>0.591140</td>\n",
       "      <td>0.980752</td>\n",
       "      <td>0.610761</td>\n",
       "      <td>0.392429</td>\n",
       "      <td>0.279317</td>\n",
       "      <td>0.414537</td>\n",
       "      <td>0.247657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.174388</td>\n",
       "      <td>0.154209</td>\n",
       "      <td>1.678751</td>\n",
       "      <td>0.507721</td>\n",
       "      <td>0.661812</td>\n",
       "      <td>0.469164</td>\n",
       "      <td>0.516615</td>\n",
       "      <td>0.286612</td>\n",
       "      <td>1.498291</td>\n",
       "      <td>1.405413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.439443</td>\n",
       "      <td>1.039569</td>\n",
       "      <td>0.051056</td>\n",
       "      <td>0.350483</td>\n",
       "      <td>0.724283</td>\n",
       "      <td>0.405356</td>\n",
       "      <td>0.662700</td>\n",
       "      <td>0.152810</td>\n",
       "      <td>0.507256</td>\n",
       "      <td>0.486962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.136932</td>\n",
       "      <td>0.155063</td>\n",
       "      <td>1.461972</td>\n",
       "      <td>0.203437</td>\n",
       "      <td>0.428063</td>\n",
       "      <td>0.150663</td>\n",
       "      <td>0.630323</td>\n",
       "      <td>0.451971</td>\n",
       "      <td>1.328927</td>\n",
       "      <td>1.110436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624931</td>\n",
       "      <td>0.462982</td>\n",
       "      <td>0.052585</td>\n",
       "      <td>0.283102</td>\n",
       "      <td>1.039518</td>\n",
       "      <td>0.395361</td>\n",
       "      <td>0.453809</td>\n",
       "      <td>0.170750</td>\n",
       "      <td>0.317637</td>\n",
       "      <td>0.337664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.134192</td>\n",
       "      <td>0.199276</td>\n",
       "      <td>1.111582</td>\n",
       "      <td>0.198632</td>\n",
       "      <td>0.319148</td>\n",
       "      <td>0.346117</td>\n",
       "      <td>0.626440</td>\n",
       "      <td>0.349674</td>\n",
       "      <td>1.173943</td>\n",
       "      <td>0.855536</td>\n",
       "      <td>...</td>\n",
       "      <td>0.860273</td>\n",
       "      <td>0.235937</td>\n",
       "      <td>0.075192</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>1.094479</td>\n",
       "      <td>0.503586</td>\n",
       "      <td>0.345280</td>\n",
       "      <td>0.250396</td>\n",
       "      <td>0.338614</td>\n",
       "      <td>0.257549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.178436  0.110992  1.646519  0.461198  0.576611  0.440900  0.378514   \n",
       "1    0.157798  0.182142  1.353120  0.302760  0.396004  0.293400  0.443676   \n",
       "2    0.279244  0.173864  1.204811  0.534460  0.455656  0.253122  0.358214   \n",
       "3    0.141640  0.115692  1.701929  0.543042  0.615419  0.434615  0.388934   \n",
       "4    0.194263  0.224569  1.435983  0.387076  0.667164  1.001340  0.635107   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "145  0.154442  0.177273  1.153289  0.312910  0.452722  0.187168  0.375944   \n",
       "146  0.129999  0.200820  1.077242  0.186530  0.494382  0.203442  0.653930   \n",
       "147  0.174388  0.154209  1.678751  0.507721  0.661812  0.469164  0.516615   \n",
       "148  0.136932  0.155063  1.461972  0.203437  0.428063  0.150663  0.630323   \n",
       "149  0.134192  0.199276  1.111582  0.198632  0.319148  0.346117  0.626440   \n",
       "\n",
       "          7         8         9    ...       502       503       504  \\\n",
       "0    0.234400  1.356820  1.447873  ...  0.412051  1.002263  0.062367   \n",
       "1    0.235815  1.362739  1.114463  ...  0.748258  0.325900  0.073889   \n",
       "2    0.369609  1.148496  0.855464  ...  0.608319  0.399806  0.100406   \n",
       "3    0.364442  1.280295  1.498631  ...  0.356081  1.112890  0.094736   \n",
       "4    0.232524  1.038372  0.860122  ...  0.773579  0.484655  0.131175   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "145  0.239255  1.366748  0.920817  ...  0.796336  0.431720  0.063977   \n",
       "146  0.407251  1.314530  0.551926  ...  0.795509  0.336958  0.080450   \n",
       "147  0.286612  1.498291  1.405413  ...  0.439443  1.039569  0.051056   \n",
       "148  0.451971  1.328927  1.110436  ...  0.624931  0.462982  0.052585   \n",
       "149  0.349674  1.173943  0.855536  ...  0.860273  0.235937  0.075192   \n",
       "\n",
       "          505       506       507       508       509       510       511  \n",
       "0    0.291720  0.514440  0.285739  0.545336  0.095519  0.406564  0.453166  \n",
       "1    0.395346  0.848227  0.415397  0.433709  0.223282  0.281199  0.227835  \n",
       "2    0.550980  1.274041  0.404865  0.284395  0.353530  0.579028  0.341356  \n",
       "3    0.261186  0.535325  0.439572  0.627597  0.107170  0.455620  0.319513  \n",
       "4    0.604059  1.274567  0.444980  0.838310  0.115054  0.649787  0.242541  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "145  0.343481  0.856915  0.324841  0.377139  0.310673  0.318942  0.454552  \n",
       "146  0.591140  0.980752  0.610761  0.392429  0.279317  0.414537  0.247657  \n",
       "147  0.350483  0.724283  0.405356  0.662700  0.152810  0.507256  0.486962  \n",
       "148  0.283102  1.039518  0.395361  0.453809  0.170750  0.317637  0.337664  \n",
       "149  0.543210  1.094479  0.503586  0.345280  0.250396  0.338614  0.257549  \n",
       "\n",
       "[150 rows x 512 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize scaler for autoencoder\n",
    "standard_scaler = init_scaler(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling source dataset\n",
    "train_scaled = scale_dataset(train, standard_scaler)\n",
    "test_scaled = scale_dataset(test, standard_scaler)\n",
    "val_scaled = scale_dataset(val, standard_scaler)\n",
    "# scaling drifted dataset\n",
    "val_intensity_scaled = scale_dataset(val_intensity, standard_scaler)\n",
    "val_gaussian_1_scaled = scale_dataset(val_gaussian_1, standard_scaler)\n",
    "val_gaussian_10_scaled = scale_dataset(val_gaussian_10, standard_scaler)\n",
    "val_gaussian_100_scaled = scale_dataset(val_gaussian_100, standard_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\umap\\umap_.py:1943: UserWarning: n_jobs value -1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From c:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\xausa\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "7/7 [==============================] - 2s 53ms/step - loss: 0.3578 - mae: 0.3578 - val_loss: 0.3115 - val_mae: 0.3115\n",
      "Epoch 2/15\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.2670 - mae: 0.2670 - val_loss: 0.2135 - val_mae: 0.2135\n",
      "Epoch 3/15\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1864 - mae: 0.1864 - val_loss: 0.1677 - val_mae: 0.1677\n",
      "Epoch 4/15\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1554 - mae: 0.1554 - val_loss: 0.1526 - val_mae: 0.1526\n",
      "Epoch 5/15\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1447 - mae: 0.1447 - val_loss: 0.1470 - val_mae: 0.1470\n",
      "Epoch 6/15\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1403 - mae: 0.1403 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 7/15\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1366 - mae: 0.1366 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 8/15\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1304 - mae: 0.1304 - val_loss: 0.1311 - val_mae: 0.1311\n",
      "Epoch 9/15\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.1211 - mae: 0.1211 - val_loss: 0.1220 - val_mae: 0.1220\n",
      "Epoch 10/15\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1124 - mae: 0.1124 - val_loss: 0.1157 - val_mae: 0.1157\n",
      "Epoch 11/15\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1070 - mae: 0.1070 - val_loss: 0.1126 - val_mae: 0.1126\n",
      "Epoch 12/15\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.1046 - mae: 0.1046 - val_loss: 0.1106 - val_mae: 0.1106\n",
      "Epoch 13/15\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1032 - mae: 0.1032 - val_loss: 0.1102 - val_mae: 0.1102\n",
      "Epoch 14/15\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.1026 - mae: 0.1026 - val_loss: 0.1090 - val_mae: 0.1090\n",
      "Epoch 15/15\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1017 - mae: 0.1017 - val_loss: 0.1089 - val_mae: 0.1089\n"
     ]
    }
   ],
   "source": [
    "# initialize dimensionality reduction\n",
    "reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer = initialize_DimReduction(seed_metrics, test,  train_scaled, test_scaled, k=k)   #k not specified: k=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 1ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "5/5 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "# Apply dimensionality reduction\n",
    "test_dim_red, info_drift = reduced_on_drift_kdim(test,  info_dataset,  reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer, )\n",
    "val_dim_red, info_drift_val= reduced_on_drift_kdim(val,  info_dataset,  reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer,)\n",
    "#  on drifted\n",
    "gau1_dim_red, info_drift_g1 = reduced_on_drift_kdim(val_gaussian_1, info_dataset, reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer ,  sigma=1, drift='Gaussian')\n",
    "gau10_dim_red, info_drift_g10 = reduced_on_drift_kdim(val_gaussian_10, info_dataset, reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer,   sigma=10, drift='Gaussian')\n",
    "gau100_dim_red, info_drift_g100 = reduced_on_drift_kdim(val_gaussian_100, info_dataset, reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer,   sigma=100, drift='Gaussian')\n",
    "intensity_dim_red, info_drift_i = reduced_on_drift_kdim(val_intensity, info_dataset, reducer_pca, reducer_umap, U_encoder_layer, T_encoder_layer ,  sigma=42, drift='intensity')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_on_reduced_kdim(val, test,  val_dim_red, test_dim_red, seed_metrics, resultFile, info_drift = info_drift_val, k=k)\n",
    "test_on_reduced_kdim(val_gaussian_1, test, gau1_dim_red, test_dim_red,  seed_metrics, resultFile, info_drift_g1, k)\n",
    "test_on_reduced_kdim(val_gaussian_10, test,  gau10_dim_red, test_dim_red, seed_metrics, resultFile, info_drift_g10, k)\n",
    "test_on_reduced_kdim(val_gaussian_100, test, gau100_dim_red, test_dim_red,  seed_metrics, resultFile, info_drift_g100, k)\n",
    "test_on_reduced_kdim(val_intensity, test, intensity_dim_red, test_dim_red, seed_metrics, resultFile, info_drift_i, k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
